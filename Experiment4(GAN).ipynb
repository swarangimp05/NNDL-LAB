{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarangimp05/NNDL-LAB/blob/main/Experiment4(GAN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 4: Implementation of GAN"
      ],
      "metadata": {
        "id": "gtOgrgKkgHji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ydVCS9-NOraJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sjevwEu0PAte",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "257cfb23-26a7-44ed-9d3e-6957396ab720"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u2oyBoPIPFD4"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kNKZ3qFPeYJ"
      },
      "source": [
        "**Load and prepare the dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA4f7TDBPjH-"
      },
      "source": [
        "You will use the MNIST dataset to train the generator and the discriminator. The generator will generate handwritten digits resembling the MNIST data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z7zr9XjVPR-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3962166-2852-4a22-d166-739343894672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nI-oj-3kPo0k"
      },
      "outputs": [],
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nXAz5H0jPq66"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "423knY9RPtYP"
      },
      "outputs": [],
      "source": [
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mDCw2z4PP98y"
      },
      "outputs": [],
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Faqs2riZP-u9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1d20293d-7276-4746-d46c-0747b7b82462"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f01301c1d10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bItmQV6QFTo"
      },
      "source": [
        "The Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Vw4qj8FmQCU2"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wyjRQpGsQPTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc2004e-8724-4bfd-d7c5-ad7e1e280cab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.0015672]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "discriminator = make_discriminator_model()\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRPF9rmRQS32"
      },
      "source": [
        "**Define the loss and optimizers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iHmExb-oQP2n"
      },
      "outputs": [],
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq0nJxqOQYeG"
      },
      "source": [
        "**Discriminator loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "toifLk4YQVnw"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3W8UA59QgLU"
      },
      "source": [
        "**Generator loss**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kkqqEvSxQigd"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8yyeumNqQjwv"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly9XRwjzQoBz"
      },
      "source": [
        "**Save checkpoints**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4aqSmuwLQllF"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVtjO0rnQtaL"
      },
      "source": [
        "**Define the training loop**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NevcSnX8QrbE"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ngLmm4BGQ0CI"
      },
      "outputs": [],
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EIxow2GLQ0_Y"
      },
      "outputs": [],
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 15 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9BP0mojQ5Qj"
      },
      "source": [
        "**Generate and save images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VWMbxPfJQ44A"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4J7Sd4bRAro"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b42C3UUtQ2xS"
      },
      "outputs": [],
      "source": [
        "train(train_dataset, EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-EiIyTRRQ7Y"
      },
      "source": [
        "**Restore the latest checkpoint.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fefnKj08RD3z"
      },
      "outputs": [],
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkFuD_H6RhUE"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Experiment4(GAN).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbnj9/t41k3xSOTAAZdPVW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}